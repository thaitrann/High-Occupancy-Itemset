{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "# from data_test import *\n",
    "# from mushroom import *\n",
    "# from retail_transaction_dataset import *\n",
    "# from fruithut.fruithut import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "data = {\n",
    "    'Tid': ['T1', 'T2', 'T3', 'T4', 'T5', 'T6'],\n",
    "    'Items': [['a', 'c', 'd'],\n",
    "              ['a', 'b', 'd'],\n",
    "              ['b', 'c', 'd', 'e'],\n",
    "              ['a', 'd'],\n",
    "              ['c', 'd', 'e'],\n",
    "              ['a', 'b', 'c', 'd', 'e']]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# data = {\n",
    "#     'Tid': ['T1', 'T2', 'T3', 'T4', 'T5', 'T6'],\n",
    "#     'Items': [['apple', 'cherry', 'durian'],\n",
    "#               ['apple', 'banana', 'durian'],\n",
    "#               ['banana', 'cherry', 'durian', 'elderberry'],\n",
    "#               ['apple', 'durian'],\n",
    "#               ['cherry', 'durian', 'elderberry'],\n",
    "#               ['apple', 'banana', 'cherry', 'durian', 'elderberry']]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "df['Item_Length'] = df['Items'].apply(lambda items: len(items))\n",
    "len_df = len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = sorted(df['Items'].explode().unique()) # get unique item => save to list\n",
    "unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_transaction = df[\"Items\"].apply(len)\n",
    "if length_transaction.nunique() == 1:\n",
    "    hastheSameLengh = True\n",
    "else:\n",
    "    hastheSameLengh = False\n",
    "\n",
    "hastheSameLengh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_transaction = length_transaction.to_list()\n",
    "length_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stset: {'a': [T1, T2, T4, T6]} - list Tid containing unique item\n",
    "def cal_stset(df):\n",
    "    stset = {} \n",
    "    for item in unique_items:\n",
    "        tid_list = df[df['Items'].apply(lambda items: item in items)]['Tid'].tolist() # create column Items with items in unique item\n",
    "        tid_lengths = [len(df[df['Tid'] == tid]['Items'].iloc[0]) for tid in tid_list if item in df[df['Tid'] == tid]['Items'].iloc[0]]\n",
    "        stset[item] = {\"StSet\": tid_list, \"Length_transaction\": tid_lengths} # add value with item_key\n",
    "\n",
    "    df_stset = pd.DataFrame.from_dict(stset, orient = 'index').reset_index()\n",
    "    df_stset.columns = [\"Items\", \"StSet\", \"Length_transaction\"]\n",
    "    df_stset['Items'] = df_stset['Items'].apply(lambda x: [x]) \n",
    "    return df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate support - count number of Tid containing unique item\n",
    "def cal_support(df_stset):\n",
    "    df_stset['Support'] = df_stset['StSet'].apply(len)\n",
    "    return df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stset = cal_stset(df)\n",
    "df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stset = cal_support(df_stset)\n",
    "df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex: 'a': {'l(a)': [2, 3, 5], 'n(a)': [1, 2, 1]}\n",
    "def df_prepare_UBO(df_stset):\n",
    "    l_item_list = []\n",
    "    n_item_list = []\n",
    "    for index, row in df_stset.iterrows():\n",
    "        item = row['Items']\n",
    "        length_transaction = row['Length_transaction']\n",
    "\n",
    "        l_item = sorted(set(length_transaction)) # get unique len(Tid) => sort ascending\n",
    "\n",
    "        counter = Counter(length_transaction)\n",
    "        n_item = [counter[i] for i in l_item] # count unique len(Tid) in occupancy_list => same index with l_item\n",
    "        \n",
    "        l_item_list.append(l_item)\n",
    "        n_item_list.append(n_item)\n",
    "    \n",
    "    df_stset = df_stset.assign(l_item=l_item_list, n_item=n_item_list)\n",
    "    return df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate occupancy - O(P) = ∑ T ∈ STSet(P) |P|/|T|\n",
    "# |P|: len(unique item) itemset {a} =>1\n",
    "# |T|: len(Tid) 1/3 + 1/3 + 1/2 + 1/5 \n",
    "def cal_occupancy(df_stset):\n",
    "    occupancy_data = []\n",
    "    for index, row in df_stset.iterrows():\n",
    "        item = row['Items']\n",
    "        length_transaction = row['Length_transaction']\n",
    "        total = 0\n",
    "        for length in length_transaction:\n",
    "            total += len(item) / length\n",
    "        occupancy_data.append({'Items': item, 'Occupancy': round(total, 2)})\n",
    "    \n",
    "    df_occupancy = pd.DataFrame(occupancy_data)\n",
    "    df_stset['Occupancy'] = df_occupancy['Occupancy']\n",
    "    return df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stset = cal_occupancy(df_stset)\n",
    "df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate according to the formula: ni x lx/li\n",
    "def cal_ubo(l, n):\n",
    "    total = 0\n",
    "    for i in range(len(l)):\n",
    "        total += n[i] * l[0] / l[i]\n",
    "    return round(total, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize: ∑ni x lx/li => save to list \n",
    "def ubo_final(length, number_transaction):\n",
    "    ubo = []\n",
    "    for i in range(len(length)): \n",
    "        # ex: len = [2,3,5], num_trans = [1,2,1]\n",
    "        # i = 0 => len = [2,3,5], num_trans = [1,2,1]\n",
    "        # i = 1 => len = [3,5], num_trans = [2,1]\n",
    "        # ...\n",
    "        ubo.append(cal_ubo(length[i:], number_transaction[i:])) # save result cal_ubo for each i => get maxUBO\n",
    "    return ubo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max from summarize => save max value in UBO by key\n",
    "def calculate_maxUBO(df_UBO):\n",
    "    df_UBO['List_UBO'] = None # create new column\n",
    "    df_UBO['Max_UBO'] = None # create new column\n",
    "    for index, row in df_UBO.iterrows():\n",
    "        length = row['l_item'] #get list of len(Tid) containing unique item\n",
    "        number_transaction = row['n_item'] # count unique len(Tid) in occupancy_list\n",
    "        \n",
    "        ubo = ubo_final(length, number_transaction) # get list of UBO by i. ex: [2.73, 2.6, 1.0]\n",
    "        max_ubo = max(ubo) # max list of UBO\n",
    "        \n",
    "        df_UBO.at[index, 'List_UBO'] = ubo # save result in df\n",
    "        df_UBO.at[index, 'Max_UBO'] = max_ubo # save result in df\n",
    "        \n",
    "    return df_UBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UBO calculation methods: main function\n",
    "def cal_UBO(df_stset): \n",
    "    df_stset = df_prepare_UBO(df_stset)    \n",
    "    df_stset = calculate_maxUBO(df_stset)\n",
    "    return df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stset = cal_UBO(df_stset)\n",
    "df_stset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_hoi_1_itemset(threshold, hastheSameLengh, df_stset):\n",
    "    C1 = []\n",
    "    HOI1 = []\n",
    "    for index, row in df_stset.iterrows():\n",
    "        item = row['Items'] # 1-itemset in row\n",
    "        support = row['Support'] # support of 1-itemset\n",
    "        occupancy = row['Occupancy'] # occuopancy of 1-itemset\n",
    "        max_ubo = row['Max_UBO'] # max_ubo of 1-itemset\n",
    "        \n",
    "        if support >= threshold:\n",
    "            if hastheSameLengh is False:\n",
    "                if max_ubo >= threshold:\n",
    "                    C1.append(item)\n",
    "                    if occupancy >= threshold:\n",
    "                        HOI1.append(item)\n",
    "            else:\n",
    "                C1.append(item)\n",
    "                if occupancy >= threshold:\n",
    "                    HOI1.append(item)\n",
    "    \n",
    "    return C1, HOI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_intersection(items1, items2, df_stset):    \n",
    "    df_intersection = pd.DataFrame(columns=['Items', 'StSet'])\n",
    "    # set1 = set(items1)\n",
    "    # set2 = set(items2)\n",
    "    list_item = sorted(list(set(items1) | set(items2)))\n",
    "    \n",
    "    list_occupancy_item = []\n",
    "    \n",
    "    for i in list_item:\n",
    "        list_occupancy_item.append(df_stset[df_stset['Items'].apply(lambda item: i in item)][\"StSet\"].iloc[0])\n",
    "        \n",
    "    intersection_list = set(list_occupancy_item[0])\n",
    "    for sublist in list_occupancy_item[1:]:\n",
    "        intersection_list = intersection_list.intersection(sublist)\n",
    "\n",
    "    intersection_list = sorted(intersection_list, key = lambda x: x[0])\n",
    "    \n",
    "    df_intersection = df_intersection.append({'Items': list_item, 'StSet': intersection_list}, ignore_index=True)\n",
    "    df_intersection['Length_transaction'] = df_intersection['StSet'].apply(lambda x: [len(df[df['Tid'] == tid]['Items'].iloc[0]) for tid in x])\n",
    "    return df_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = ['a']\n",
    "# test2 = ['b']\n",
    "# df_intersection(test1, test2, df_stset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_equivalence_class(P1, P2):\n",
    "    if len(P1) == len(P2):\n",
    "        if len(P1) == 1:\n",
    "            if P1 == P2:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            if P1 == P2:\n",
    "                return False\n",
    "            else:\n",
    "                new_P1 = P1[:-1]\n",
    "                new_P2 = P2[:-1]\n",
    "                if new_P1 == new_P2:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    else:\n",
    "        return False\n",
    "        # else:\n",
    "        #     intersection_P1_P2 = sorted(list(set(P1) & set(P2)))\n",
    "        #     print(intersection_P1_P2)\n",
    "        #     if len(intersection_P1_P2) == len(P1) - 1:\n",
    "        #         for element in intersection_P1_P2:\n",
    "        #             if P1.index(element) != P2.index(element):\n",
    "        #                 return False\n",
    "        #         return True\n",
    "        #     else:\n",
    "        #         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ['a']\n",
    "test2 = ['b']\n",
    "print(is_same_equivalence_class(test1, test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_occupancy_candidate(items):    \n",
    "    df_candidate = pd.DataFrame(columns=['Items', 'StSet'])\n",
    "    \n",
    "    list_stset_item = []\n",
    "    \n",
    "    for i in items:\n",
    "        list_stset_item.append(df_stset[df_stset['Items'].apply(lambda item: i in item)][\"StSet\"].iloc[0])\n",
    "        \n",
    "    intersection_list = set(list_stset_item[0])\n",
    "    for sublist in list_stset_item[1:]:\n",
    "        intersection_list = intersection_list.intersection(sublist)\n",
    "    \n",
    "    intersection_list = sorted(intersection_list, key = lambda x: x[0])\n",
    "    \n",
    "    df_candidate = df_candidate.append({'Items': items, 'StSet': intersection_list}, ignore_index=True)\n",
    "    df_candidate['Length_transaction'] = df_candidate['StSet'].apply(lambda x: [len(df[df['Tid'] == tid]['Items'].iloc[0]) for tid in x])\n",
    "    df_candidate = cal_occupancy(df_candidate)\n",
    "    return df_candidate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = ['a','b','d']\n",
    "# df_test = cal_occupancy_candidate(test)['Occupancy'].iloc[0]\n",
    "# print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_hoi_k_itemset(threshold, hastheSameLengh, CK_minus_1, df_stset):\n",
    "    CK = []\n",
    "    HOIK = []\n",
    "    \n",
    "    while len(CK_minus_1) > 0:\n",
    "        P1 = sorted(CK_minus_1[0])\n",
    "        for P2 in CK_minus_1:\n",
    "            sorted(P2)\n",
    "            if is_same_equivalence_class(P1, P2):\n",
    "                P = df_intersection(P1, P2, df_stset)\n",
    "                P_items = P['Items'].iloc[0]\n",
    "                P_stset = P['StSet'].iloc[0]\n",
    "                if len(P_stset) >= threshold:\n",
    "                    if hastheSameLengh is False:\n",
    "                        P_ubo = cal_UBO(P)['Max_UBO'].iloc[0]\n",
    "                        if P_ubo >= threshold:\n",
    "                            CK.append(P_items)\n",
    "                    else:\n",
    "                        CK.append(P_items)\n",
    "                        \n",
    "        CK_minus_1.pop(0)\n",
    "    \n",
    "    for i in CK:\n",
    "        if cal_occupancy_candidate(i)['Occupancy'].iloc[0] >= threshold:\n",
    "            HOIK.append(i)\n",
    "    \n",
    "    return CK, HOIK\n",
    "        \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test FHOI\n",
    "HOIS = []\n",
    "C1 = []\n",
    "HOI1 = []\n",
    "CK_minus_1 = []\n",
    "\n",
    "k = 2 # loop to create 2-itemset\n",
    "threshold = 0.25 \n",
    "threshold = threshold * len_df # ex: threshold = 25% of len(database)\n",
    "start_time = time.time()\n",
    "\n",
    "#create candidate 1 and HOI1 itemset\n",
    "C1, HOI1 = mine_hoi_1_itemset(threshold, hastheSameLengh, df_stset)\n",
    "\n",
    "HOIS = HOI1\n",
    "CK_minus_1 = C1\n",
    "\n",
    "while CK_minus_1:\n",
    "    CK, HOIK = mine_hoi_k_itemset(threshold, hastheSameLengh, CK_minus_1, df_stset)\n",
    "    print(HOIK)\n",
    "    # HOIS.append(HOIK)\n",
    "    CK_minus_1 = CK\n",
    "    k += 1\n",
    "\n",
    "for i in HOIS:\n",
    "    print(i)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "#update try except\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_depth_hois(threshold, hastheSameLengh, C1, df_stset, HOIS):\n",
    "    for i in range(len(C1)):\n",
    "        P1 = C1[i]\n",
    "        C_l = []\n",
    "        for j in range(i + 1, len(C1)):\n",
    "            P2 = C1[j]\n",
    "            P = df_intersection(P1, P2, df_stset)\n",
    "            P_items = P['Items'].iloc[0]\n",
    "            P_stset = P['StSet'].iloc[0]\n",
    "            if len(P_stset) >= threshold:\n",
    "                if hastheSameLengh is False:\n",
    "                    P_ubo = cal_UBO(P)['Max_UBO'].iloc[0]\n",
    "                    if P_ubo >= threshold:\n",
    "                        C_l.append(P_items)\n",
    "                else:\n",
    "                    C_l.append(P_items)\n",
    "        mine_depth_hois(threshold, hastheSameLengh, C_l, df_stset, HOIS)\n",
    "        \n",
    "        for i in C_l:\n",
    "            if cal_occupancy_candidate(i)['Occupancy'].iloc[0] >= threshold:\n",
    "                HOIS.append(i)\n",
    "    \n",
    "    return HOIS\n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:2895\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2896\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1675\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1683\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'List_UBO'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3574\u001b[0m, in \u001b[0;36mNDFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3574\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:2897\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 2897\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   2899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'List_UBO'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m HOIS \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m C1:\n\u001b[1;32m---> 18\u001b[0m     HOIS_\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmine_depth_hois\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhastheSameLengh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_stset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHOIS\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m HOIS:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m, in \u001b[0;36mmine_depth_hois\u001b[1;34m(threshold, hastheSameLengh, C1, df_stset, HOIS)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m             C_l\u001b[38;5;241m.\u001b[39mappend(P_items)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmine_depth_hois\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhastheSameLengh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_stset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHOIS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m C_l:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cal_occupancy_candidate(i)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOccupancy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m, in \u001b[0;36mmine_depth_hois\u001b[1;34m(threshold, hastheSameLengh, C1, df_stset, HOIS)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m             C_l\u001b[38;5;241m.\u001b[39mappend(P_items)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmine_depth_hois\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhastheSameLengh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_stset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHOIS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m C_l:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cal_occupancy_candidate(i)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOccupancy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m, in \u001b[0;36mmine_depth_hois\u001b[1;34m(threshold, hastheSameLengh, C1, df_stset, HOIS)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(P_stset) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hastheSameLengh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m         P_ubo \u001b[38;5;241m=\u001b[39m \u001b[43mcal_UBO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax_UBO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m P_ubo \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[0;32m     14\u001b[0m             C_l\u001b[38;5;241m.\u001b[39mappend(P_items)\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mcal_UBO\u001b[1;34m(df_stset)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_UBO\u001b[39m(df_stset): \n\u001b[0;32m      3\u001b[0m     df_stset \u001b[38;5;241m=\u001b[39m df_prepare_UBO(df_stset)    \n\u001b[1;32m----> 4\u001b[0m     df_stset \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_maxUBO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_stset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_stset\n",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m, in \u001b[0;36mcalculate_maxUBO\u001b[1;34m(df_UBO)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_maxUBO\u001b[39m(df_UBO):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mdf_UBO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mList_UBO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# create new column\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     df_UBO[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax_UBO\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# create new column\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_UBO\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3044\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3043\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3044\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3121\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_valid_index(value)\n\u001b[0;32m   3120\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(key, value)\n\u001b[1;32m-> 3121\u001b[0m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3123\u001b[0m \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   3124\u001b[0m \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   3126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3577\u001b[0m, in \u001b[0;36mNDFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3574\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 3577\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   3580\u001b[0m NDFrame\u001b[38;5;241m.\u001b[39m_iset_item(\u001b[38;5;28mself\u001b[39m, loc, value)\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1204\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blknos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, loc, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tgtha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:5499\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5497\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5498\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test DFHOI\n",
    "HOIS = []\n",
    "C1 = []\n",
    "HOI1 = []\n",
    "CK_minus_1 = []\n",
    "\n",
    "k = 2 # loop to create 2-itemset\n",
    "threshold = 0.25 \n",
    "threshold = threshold * len_df # ex: threshold = 25% of len(database)\n",
    "start_time = time.time()\n",
    "\n",
    "#create candidate 1 and HOI1 itemset\n",
    "C1, HOI1 = mine_hoi_1_itemset(threshold, hastheSameLengh, df_stset)\n",
    "HOIS_ = HOI1\n",
    "HOIS = []\n",
    "\n",
    "while C1:\n",
    "    HOIS_.append(mine_depth_hois(threshold, hastheSameLengh, C1, df_stset, HOIS))\n",
    "    \n",
    "for i in HOIS:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
